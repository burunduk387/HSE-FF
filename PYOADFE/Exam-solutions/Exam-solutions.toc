\babel@toc {russian}{}
\contentsline {section}{Замечания и благодарности}{3}{section*.1}%
\contentsline {section}{Структуры данных}{4}{section*.2}%
\contentsline {subsection}{Билет 1-3. O-нотация. Приведите примеры алгоритмов над структурами данных с константным и квадратичным (с линейным и логарифмическим) по числу элементов временем работы. Приведите примеры, в которых выбор асимптотически более медленного с точки зрения O-нотации алгоритма предпочтителен.}{4}{section*.3}%
\contentsline {subsection}{Билет 4. Сортировка. Приведите примеры методов сортировки.}{5}{section*.4}%
\contentsline {subsection}{Билет 5-8. Деревья. Определения: двоичное дерево, глубина дерева, сбалансированное дерево, дерево поиска, двоичное дерево поиска, минимальное и максимальное время поиска значения. Какова глубина сбалансированного двоичного дерева? Сбалансированное двоичное дерево поиска, для чего используется, время поиска значения, пример построения из упорядоченного массива.}{5}{section*.5}%
\contentsline {subsection}{Билет 9. k-мерное двоичное дерево поиска. Время поиска значения, примеры использования.}{7}{section*.6}%
\contentsline {subsection}{Хеш-таблицы.}{8}{section*.7}%
\contentsline {section}{Статистикаа}{10}{section*.8}%
\contentsline {subsection}{Билет 1-3. Формулировка задачи линейной регрессии. Идея и постановка задачи определения параметров линии регрессии методом наименьших квадратов.Идея и постановка задачи определения параметров линии регрессии методом максимального правдоподобия. Сравните метод максимального правдоподобия и метод наименьших квадратов. В каких случаях они применяются, как выбрать тот или иной метод.}{10}{section*.9}%
\contentsline {subsection}{Билет 4-5. Метод максимального правдоподобия: покажите как методом максимального правдоподобия получить параметр пуассоновского распределения по набору измерений.}{13}{section*.10}%
\contentsline {subsection}{Билет 6-9. Проверка статистических гипотез. Нулевая и альтернативная гипотеза. Ошибки первого и второго рода. Идея t-критерия Стьюдента. Идея $\chi ^{2}$-критерия Пирсона. Идея критерия Колмогорова. }{14}{section*.11}%
\contentsline {subsection}{Билет 10. Стохастические процессы. Как автокорреляционная функция позволяет их изучать.}{17}{section*.12}%
\contentsline {section}{Оптимизация}{19}{section*.13}%
\contentsline {section}{Машинное обучение}{27}{Item.20}%
\contentsline {subsection}{Билет 1. Основная идея подхода к решению задач методами машинного обучения. Фундаментальное ограничение машинного обучения.}{28}{section*.15}%
\contentsline {subsection}{Билет 2-3, 9. Классификация методов машинного обучения. Приведите примеры задач каждого класса. Задача классификации с учителем. Примеры. Методы машинного обучения без учителя. Приведите примеры задач.}{29}{section*.16}%
\contentsline {subsection}{Билет 4. Функция потерь в задачах машинного обучения.}{31}{section*.17}%
\contentsline {subsection}{Билет 5. Понятие переобучения. Тестовая выборка.}{32}{equation.0.1}%
\contentsline {subsection}{Билет 6. Идея метода k ближайших соседей (kNN).}{32}{section*.19}%
\contentsline {subsection}{Билет 7. Гиперпараметры и валидационная выборка.}{33}{section*.20}%
\contentsline {subsection}{Билет 8. Задача регрессии с учителем. Примеры. Популярные алгоритмы решения.}{33}{section*.21}%
\contentsline {subsection}{Билет 10. Идея метода нейронных сетей.}{34}{section*.22}%
\contentsline {subsection}{Билет 11. Идея методов random forest и gradient boosting.}{35}{section*.23}%
\contentsline {subsection}{Билет 12. Приведите примеры физических задач для которых подходит и не подходит машинное обучение.}{36}{section*.24}%
