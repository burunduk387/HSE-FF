\relax 
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{russian}{}
\@writefile{toc}{\contentsline {section}{Замечания и благодарности}{3}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Структуры данных}{4}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 1-3. O-нотация. Приведите примеры алгоритмов над структурами данных с константным и квадратичным (с линейным и логарифмическим) по числу элементов временем работы. Приведите примеры, в которых выбор асимптотически более медленного с точки зрения O-нотации алгоритма предпочтителен.}{4}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 4. Сортировка. Приведите примеры методов сортировки.}{5}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 5-8. Деревья. Определения: двоичное дерево, глубина дерева, сбалансированное дерево, дерево поиска, двоичное дерево поиска, минимальное и максимальное время поиска значения. Какова глубина сбалансированного двоичного дерева? Сбалансированное двоичное дерево поиска, для чего используется, время поиска значения, пример построения из упорядоченного массива.}{5}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 9. k-мерное двоичное дерево поиска. Время поиска значения, примеры использования.}{7}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Статистикаа}{8}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 1-3. Формулировка задачи линейной регрессии. Идея и постановка задачи определения параметров линии регрессии методом наименьших квадратов.Идея и постановка задачи определения параметров линии регрессии методом максимального правдоподобия. Сравните метод максимального правдоподобия и метод наименьших квадратов. В каких случаях они применяются, как выбрать тот или иной метод.}{9}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 4-5. Метод максимального правдоподобия: покажите как методом максимального правдоподобия получить параметр пуассоновского распределения по набору измерений.}{11}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 6-9. Проверка статистических гипотез. Нулевая и альтернативная гипотеза. Ошибки первого и второго рода. Идея t-критерия Стьюдента. Идея $\chi ^{2}$-критерия Пирсона. Идея критерия Колмогорова. }{13}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 10. Стохастические процессы. Как автокорреляционная функция позволяет их изучать.}{15}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Оптимизация}{16}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 1. Задачи оптимизации. Их классификация. Примеры}{17}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Машинное обучение}{17}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 1. Основная идея подхода к решению задач методами машинного обучения. Фундаментальное ограничение машинного обучения.}{17}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 2-3, 9. Классификация методов машинного обучения. Приведите примеры задач каждого класса. Задача классификации с учителем. Примеры. Методы машинного обучения без учителя. Приведите примеры задач.}{18}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 4. Функция потерь в задачах машинного обучения.}{20}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 5. Понятие переобучения. Тестовая выборка.}{21}{equation.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 6. Идея метода k ближайших соседей (kNN).}{21}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 7. Гиперпараметры и валидационная выборка.}{22}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 8. Задача регрессии с учителем. Примеры. Популярные алгоритмы решения.}{22}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 10. Идея метода нейронных сетей.}{23}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 11. Идея методов random forest и gradient boosting.}{24}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Билет 12. Приведите примеры физических задач для которых подходит и не подходит машинное обучение.}{25}{section*.24}\protected@file@percent }
\newlabel{LastPage}{{}{25}{}{page.25}{}}
\xdef\lastpage@lastpage{25}
\xdef\lastpage@lastpageHy{25}
